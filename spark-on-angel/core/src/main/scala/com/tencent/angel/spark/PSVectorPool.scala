package com.tencent.angel.spark

import org.apache.spark.SparkException

/**
 * PSVectorPool delegate a memory space on PS servers,
 * which hold `capacity` number vectors with `numDimensions` dimension.
 * The dimension of PSVectors in one PSVectorPool is the same.
 *
 * A PSVectorPool is like a Angel Matrix.
 *
 * @param client The PSClient to create pool
 * @param id PSVectorPool unique id
 * @param numDimensions Dimension of vectors
 * @param capacity Capacity of pool
 */
abstract class PSVectorPool(
    private val client: PSClient,
    private[spark] val id: Int,
    val numDimensions: Int,
    val capacity: Int) {

  private[spark] def allocate(): PSVectorProxy

  /**
   * Create a PSVector with a local Double Array
   *
   * @param value The local Double Array
   */
  def create(value: Array[Double]): PSVectorProxy = {
    assertCompatible(value)
    val vector = allocate()
    client.put(vector, value)
    vector
  }

  /**
   * Create a PSVector filled with a local Double value
    *
    * @param value the local Double value
   */
  def create(value: Double): PSVectorProxy = {
    val vector = allocate()
    client.fill(vector, value)
    vector
  }

  /**
   * Return a zero PSVector
   */
  def createZero(): PSVectorProxy = create(0.0)

  /**
   * Create a random PSVector, the elements is generated by uniform distribution
   *
   * @param min the uniform distribution parameter: minimum boundary
   * @param max the uniform distribution parameter: maximum boundary
   */
  def createRandomUniform(min: Double, max: Double): PSVectorProxy = {
    val vector = allocate()
    client.randomUniform(vector, min, max)
    vector
  }

  /**
   * Create a random PSVector, the elements is generated by normal distribution
   *
   * @param mean the uniform distribution parameter: mean
   * @param stddev the uniform distribution parameter: standard deviation
   */
  def createRandomNormal(mean: Double, stddev: Double): PSVectorProxy = {
    val vector = allocate()
    client.randomNormal(vector, mean, stddev)
    vector
  }

  /**
   * Make sure dimension compatible
   */
  private def assertCompatible(other: Array[Double]): Unit = {
    if (this.numDimensions != other.length) {
      throw new SparkException(s"The target array's dimension " +
        s"does not match this vector pool! \n" +
        s"pool dimension is $numDimensions," +
        s"but target array's dimension is ${other.length}")
    }
  }

  /**
   * Delete a PSVector from this PSVectorPool
   */
  private[spark] def delete(key: PSVectorProxy): Unit

  /**
   * Destroy this PSVectorPool
   */
  private[spark] def destroy(): Unit

}
